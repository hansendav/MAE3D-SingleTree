{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2868acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "from util_yours import split_knn_patches\n",
    "from util_yours import center_split_masking\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "from data_yours import ALS_50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d2108ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ALS_50K(num_points=2048)\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=False, num_workers=0)\n",
    "batch = next(iter(dl))\n",
    "batch = batch[0]\n",
    "batch = batch.permute(0, 2, 1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f0e3b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "false INTERNAL ASSERT FAILED at \"/share/castor/home/e2405193/MAE3D/pointnet2_ops_lib/pointnet2_ops/_ext-src/src/sampling.cpp\":83, please report a bug to PyTorch. CPU not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_split_knn \u001b[38;5;241m=\u001b[39m \u001b[43msplit_knn_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../util_yours.py:170\u001b[0m, in \u001b[0;36msplit_knn_patches\u001b[0;34m(xyz, mask_ratio, nsample, random)\u001b[0m\n\u001b[1;32m    167\u001b[0m num_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(mask_ratio \u001b[38;5;241m*\u001b[39m num_patches)\n\u001b[1;32m    168\u001b[0m num_vis \u001b[38;5;241m=\u001b[39m num_patches \u001b[38;5;241m-\u001b[39m num_mask\n\u001b[0;32m--> 170\u001b[0m center_idx \u001b[38;5;241m=\u001b[39m \u001b[43mpointnet2_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfurthest_point_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    171\u001b[0m center_pos \u001b[38;5;241m=\u001b[39m index_points(xyz, center_idx)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random:\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/pointnet2_ops/pointnet2_utils.py:54\u001b[0m, in \u001b[0;36mFurthestPointSampling.forward\u001b[0;34m(ctx, xyz, npoint)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(ctx, xyz, npoint):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# type: (Any, torch.Tensor, int) -> torch.Tensor\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    Uses iterative furthest point sampling to select a set of npoint features that have the largest\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    minimum distance\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m        (B, npoint) tensor containing the set\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfurthest_point_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mmark_non_differentiable(out)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: false INTERNAL ASSERT FAILED at \"/share/castor/home/e2405193/MAE3D/pointnet2_ops_lib/pointnet2_ops/_ext-src/src/sampling.cpp\":83, please report a bug to PyTorch. CPU not supported"
     ]
    }
   ],
   "source": [
    "output_split_knn = split_knn_patches(batch, mask_ratio=0.7, nsample=16, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2406b59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_split_knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43moutput_split_knn\u001b[49m)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_split_knn[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_split_knn[i]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_split_knn' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_split_knn)):\n",
    "    print(f\"output_split_knn[{i}].shape: {output_split_knn[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ab32d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_center_split_masking \u001b[38;5;241m=\u001b[39m \u001b[43mcenter_split_masking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasking_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../util_yours.py:262\u001b[0m, in \u001b[0;36mcenter_split_masking\u001b[0;34m(batch, masking_ratio, patch_size)\u001b[0m\n\u001b[1;32m    259\u001b[0m masked_center_points \u001b[38;5;241m=\u001b[39m pc_masked[masked_centers]\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# get patch idxs\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m vis_patch_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mget_kNN_patch_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpc_vis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvis_center_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m masked_patch_idxs \u001b[38;5;241m=\u001b[39m get_kNN_patch_idxs(pc_masked, masked_center_points, k\u001b[38;5;241m=\u001b[39mpatch_size)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# get patches \u001b[39;00m\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../util_yours.py:217\u001b[0m, in \u001b[0;36mget_kNN_patch_idxs\u001b[0;34m(xyz, center_xyz, k)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_kNN_patch_idxs\u001b[39m(xyz, center_xyz, k):\n\u001b[1;32m    215\u001b[0m     dists \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcdist(xyz, center_xyz)\n\u001b[0;32m--> 217\u001b[0m     _, knn_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlargest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# shape: (N points, 3)\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m knn_idxs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "output_center_split_masking = center_split_masking(batch.cuda(), masking_ratio=0.7, patch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "046038ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_split_knn[0].shape: torch.Size([8, 0, 2, 2048])\n",
      "output_split_knn[1].shape: torch.Size([8, 1, 2, 2048])\n",
      "output_split_knn[2].shape: torch.Size([8, 0, 2048])\n",
      "output_split_knn[3].shape: torch.Size([8, 1, 2048])\n",
      "output_split_knn[4].shape: torch.Size([0])\n",
      "output_split_knn[5].shape: torch.Size([1])\n",
      "output_split_knn[6].shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_split_knn)):\n",
    "    print(f\"output_split_knn[{i}].shape: {output_split_knn[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9476758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MAE3D model \n",
    "from model_yours import MAE3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10375b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../config/experiments\"):\n",
    "    cfg = compose(config_name=\"DEBUG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7841f5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patch_size': 16, 'mask_ratio': 0.3, 'num_points': 2048, 'masking_strategy': 'xysplit', 'encoder_dims': 1024, 'decoder_dims': 1024, 'mlp_dim': 2048, 'depth': 6, 'num_heads': 8, 'dim_per_head': 64, 'dropout': 0.0, 'loss_alpha_center': 0.1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206a474",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ab7b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 2048, Patch size: 16, Mask ratio: 0.3, Vis patch num: 90, Mask patch num: 38, \n"
     ]
    }
   ],
   "source": [
    "model = MAE3D(cfg.model) \n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00447f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape before permute: torch.Size([8, 2048, 3])\n",
      "Input shape: torch.Size([8, 3, 2048])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m xyz \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../model_yours.py:252\u001b[0m, in \u001b[0;36mMAE3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    249\u001b[0m     mask_pos, vis_pos, mask_center_pos, vis_center_pos, mask_patch_idx, vis_patch_idx, shuffle_idx \u001b[38;5;241m=\u001b[39m split_knn_patches(\n\u001b[1;32m    250\u001b[0m         xyz, mask_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmask_ratio, nsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpatch_size, random\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxysplit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 252\u001b[0m     mask_pos, vis_pos, mask_center_pos, vis_center_pos, mask_patch_idx, vis_patch_idx, shuffle_idx \u001b[38;5;241m=\u001b[39m \u001b[43mcenter_split_masking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasking_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m batch_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(batch_size, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# reshuffle\u001b[39;00m\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../util_yours.py:262\u001b[0m, in \u001b[0;36mcenter_split_masking\u001b[0;34m(batch, masking_ratio, patch_size)\u001b[0m\n\u001b[1;32m    259\u001b[0m masked_center_points \u001b[38;5;241m=\u001b[39m pc_masked[masked_centers]\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# get patch idxs\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m vis_patch_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mget_kNN_patch_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpc_vis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvis_center_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m masked_patch_idxs \u001b[38;5;241m=\u001b[39m get_kNN_patch_idxs(pc_masked, masked_center_points, k\u001b[38;5;241m=\u001b[39mpatch_size)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# get patches \u001b[39;00m\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../util_yours.py:217\u001b[0m, in \u001b[0;36mget_kNN_patch_idxs\u001b[0;34m(xyz, center_xyz, k)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_kNN_patch_idxs\u001b[39m(xyz, center_xyz, k):\n\u001b[1;32m    215\u001b[0m     dists \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcdist(xyz, center_xyz)\n\u001b[0;32m--> 217\u001b[0m     _, knn_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlargest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# shape: (N points, 3)\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m knn_idxs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "model = model.cuda()  # Ensure model is on CUDA\n",
    "xyz = batch.permute(0, 2, 1).contiguous().cuda()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3008df34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2048, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, N, C = xyz.shape\n",
    "B, N, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b4430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointnet2_ops import pointnet2_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d765134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_points(points, idx):\n",
    "    device = points.device\n",
    "    idx = idx.to(device)\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14bb498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_point(nsample, xyz, new_xyz):\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    _, group_idx = torch.topk(sqrdists, nsample, dim=-1, largest=False, sorted=False)\n",
    "    return group_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05fbb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_distance(src, dst):\n",
    "    B, N, _ = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc28169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.permute(0, 2, 1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76b1a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_ratio = cfg.model.mask_ratio\n",
    "patch_size = cfg.model.patch_size\n",
    "\n",
    "B, N, C = batch.shape \n",
    "\n",
    "# calculate number of patches\n",
    "num_patches = N // patch_size # assuming N is num_points\n",
    "num_masked_patches = int(num_patches * masking_ratio) \n",
    "num_vis_patches = num_patches - num_masked_patches\n",
    "\n",
    "vis_pos = []\n",
    "mask_pos = [] \n",
    "mask_center_pos = [] \n",
    "vis_center_pos = [] \n",
    "# generate patch_idx and shuffle_idx later \n",
    "\n",
    "for i in range(B): \n",
    "    pc = batch[i]\n",
    "\n",
    "    # generate random T \n",
    "    if np.random.choice([True, False]): \n",
    "        t, axis = torch.median(pc[:,0]), 'x'\n",
    "    else: \n",
    "        t, axis = torch.median(pc[:, 1]), 'y'\n",
    "    \n",
    "    # subset the point cloud\n",
    "    if axis == 'x':\n",
    "        pc_vis = pc[pc[:, 0] > t] \n",
    "        pc_masked = pc[pc[:, 0] <= t]\n",
    "    elif axis == 'y': \n",
    "        pc_vis = pc[pc[:, 1] <= t] \n",
    "        pc_masked = pc[pc[:, 1] > t]\n",
    "\n",
    "    # find patch centers in the subsets \n",
    "    vis_centers = pointnet2_utils.furthest_point_sample(pc_vis.cuda().unsqueeze(0), num_vis_patches).cpu().squeeze(0)\n",
    "    masked_centers = pointnet2_utils.furthest_point_sample(pc_masked.cuda().unsqueeze(0), num_masked_patches).cpu().squeeze(0)\n",
    "\n",
    "    # select center points \n",
    "    vis_center_points = pc_vis[vis_centers]\n",
    "    masked_center_points = pc_masked[masked_centers]\n",
    "\n",
    "    # get patch idxs\n",
    "    vis_patch_idxs = get_kNN_patch_idxs(pc_vis, vis_center_points, k=patch_size)\n",
    "    masked_patch_idxs = get_kNN_patch_idxs(pc_masked, masked_center_points, k=patch_size)\n",
    "\n",
    "    # get patches \n",
    "    vis_patches = [pc_vis[vis_patch_idxs[:, i]] for i in range(vis_patch_idxs.shape[1])]\n",
    "    masked_patches = [pc_masked[masked_patch_idxs[:, i]] for i in range(masked_patch_idxs.shape[1])]\n",
    "\n",
    "    vis_patches_tensor = torch.stack(vis_patches, dim=0)\n",
    "    masked_patches_tensor = torch.stack(masked_patches, dim=0)\n",
    "\n",
    "    vis_pos.append(vis_patches_tensor)\n",
    "    vis_center_pos.append(vis_center_points)\n",
    "    mask_pos.append(masked_patches_tensor)\n",
    "    mask_center_pos.append(masked_center_points)\n",
    "\n",
    "vis_pos = torch.stack(vis_pos, dim=0)\n",
    "vis_center_pos = torch.stack(vis_center_pos, dim=0)\n",
    "mask_pos = torch.stack(mask_pos, dim=0)\n",
    "mask_center_pos = torch.stack(mask_center_pos, dim=0)\n",
    "\n",
    "idx_all = torch.rand(num_patches).argsort()\n",
    "vis_patch_idx = idx_all[:num_vis_patches]\n",
    "mask_patch_idx = idx_all[num_vis_patches:]\n",
    "\n",
    "shuffle_idx = torch.cat((vis_patch_idx, mask_patch_idx), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a536210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx = torch.arange(B, device=batch.device).unsqueeze(-1)\n",
    "batch_idx.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c771c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_pos = torch.cat((vis_center_pos, mask_center_pos), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb84c65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22735030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "center_pos_reshuffle = torch.empty_like(center_pos, device=center_pos.device)\n",
    "center_pos_reshuffle[batch_idx, shuffle_idx] = center_pos\n",
    "center_pos = center_pos_reshuffle\n",
    "point_pos = torch.cat((vis_pos, mask_pos), dim=1)\n",
    "point_pos_reshuffle = torch.empty_like(point_pos, device=point_pos.device)\n",
    "point_pos_reshuffle[batch_idx, shuffle_idx] = point_pos\n",
    "point_pos = point_pos_reshuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1624c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos = point_pos[batch_idx, mask_patch_idx]\n",
    "vis_pos = point_pos[batch_idx, vis_patch_idx]\n",
    "vis_pos_input = vis_pos.view(B, num_vis_patches * cfg.model.patch_size, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "647f67c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1440, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_pos_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bdf7f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7c39728",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87e7fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos_embed_encoder = model.pos_embed_encoder(center_pos)\n",
    "x_pos_embed_decoder = model.pos_embed_decoder(center_pos)\n",
    "x_pos_embed_encoder = x_pos_embed_encoder[batch_idx, vis_patch_idx].view(B, -1, cfg.model.encoder_dims)\n",
    "x_pos_embed_encoder = torch.cat((model.cls_token_encoder.repeat(B, 1, 1), x_pos_embed_encoder), dim=1)\n",
    "x_pos_embed_decoder = x_pos_embed_decoder.view(B, -1, cfg.model.decoder_dims)\n",
    "x_pos_embed_decoder = torch.cat((model.cls_token_decoder.repeat(B, 1, 1), x_pos_embed_decoder), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3430002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 91, 1024]), torch.Size([4, 129, 1024]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos_embed_encoder.shape, x_pos_embed_decoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af7b5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vis_pos_input.devie: cpu, x_pos_embed_encoder.device: cpu, x_vis.device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'vis_pos_input.devie: {vis_pos_input.device}, '\n",
    "    f'x_pos_embed_encoder.device: {x_pos_embed_encoder.device}, '\n",
    "    f'x_vis.device: {x_pos_embed_encoder.device}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "695f21e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m----> 2\u001b[0m x_vis \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvis_pos_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pos_embed_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m x_vis \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder_to_decoder(x_vis)\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../model_yours.py:324\u001b[0m, in \u001b[0;36mMAE3DEncoder.forward\u001b[0;34m(self, x, x_pos_embed)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x_pos_embed):\n\u001b[1;32m    322\u001b[0m     batch_size, num_points, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 324\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    326\u001b[0m     x \u001b[38;5;241m=\u001b[39m rearrange(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb (p n) c -> (b p) n c\u001b[39m\u001b[38;5;124m'\u001b[39m, b\u001b[38;5;241m=\u001b[39mbatch_size, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpatch_size, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mencoder_dims)\n\u001b[1;32m    327\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(x, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mae3d/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../model_yours.py:80\u001b[0m, in \u001b[0;36mPatchEmbed_DGCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 80\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mget_graph_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)  \u001b[38;5;66;03m# (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\u001b[39;00m\n",
      "File \u001b[0;32m/share/castor/home/e2405193/MAE3D-SingleTree/misc/../model_yours.py:36\u001b[0m, in \u001b[0;36mget_graph_feature\u001b[0;34m(x, k, idx, dim9)\u001b[0m\n\u001b[1;32m     32\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m idx_base \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, batch_size, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m num_points\n\u001b[0;32m---> 36\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx_base\u001b[49m\n\u001b[1;32m     38\u001b[0m idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m _, num_dims, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "model = model.cpu()\n",
    "x_vis = model.encoder(vis_pos_input, x_pos_embed_encoder)\n",
    "x_vis = model.encoder_to_decoder(x_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_full_init = model.token_init[None, None, :].repeat(B, num_patches, 1)\n",
    "x_mask_init = x_full_init[batch_idx, mask_patch_idx]\n",
    "\n",
    "x_full = torch.cat((x_vis, x_mask_init), dim=1)\n",
    "x_full_reshuffle = torch.empty_like(x_full, device=x_full.device)\n",
    "x_full_reshuffle[batch_idx, shuffle_idx] = x_full\n",
    "\n",
    "x_full = model.decoder(x_full_reshuffle, x_pos_embed_decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
